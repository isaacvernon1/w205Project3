{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# W205 Project 3 Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Command Line Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first need to clone in our git repository for project 3. We navigate to our w205 directory and use the following command\n",
    "```\n",
    "git clone https://github.com/mids-w205-crook/project-3-isaacvernon1\n",
    "```\n",
    "\n",
    "We can then navigate into this directory and copy in the initial files for docker-compose.yml and game_api.py. The changes made to these files can be found by looking at the respective files\n",
    "```\n",
    "cp ~/w205/course-content/13-Understanding-Data/docker-compose.yml ~/w205/project-3-isaacvernon1\n",
    "cp ~/w205/course-content/12-Querying-Data-II/*.py ~/w205/project-3-isaacvernon1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that everything we need has been imported, we can go ahead and bring up our cluster and check that it is brought up.\n",
    "```\n",
    "docker-compose up -d\n",
    "docker-compose ps\n",
    "docker ps -a\n",
    "```\n",
    "\n",
    "We can then create a Kafka topic \"events\" that we will log our app server events to.\n",
    "```\n",
    "docker-compose exec kafka kafka-topics --create --topic events --partitions 1 --replication-factor 1 --if-not-exists --zookeeper zookeeper:32181\n",
    "```\n",
    "\n",
    "Now that we have our Kafka topic, we will start up our flask instance server (API server)\n",
    "```\n",
    "docker-compose exec mids env FLASK_APP=/w205/project-3-isaacvernon1/game_api.py flask run --host 0.0.0.0\n",
    "```\n",
    "\n",
    "With our API (Flask) server set up, we can now use Apache Bench to generate some test data for our pipeline.\n",
    "```\n",
    "docker-compose exec mids ab -n 10 -H \"Host: user1.comcast.com\" http://localhost:5000/\n",
    "docker-compose exec mids ab -n 10 -H \"Host: user1.comcast.com\" http://localhost:5000/purchase_a_sword\n",
    "docker-compose exec mids ab -n 10 -H \"Host: user1.comcast.com\" http://localhost:5000/buy_a_sword\n",
    "docker-compose exec mids ab -n 10 -H \"Host: user1.comcast.com\" http://localhost:5000/join_guild\n",
    "docker-compose exec mids ab -n 10 -H \"Host: user2.att.com\" http://localhost:5000/\n",
    "docker-compose exec mids ab -n 10 -H \"Host: user2.att.com\" http://localhost:5000/purchase_a_sword\n",
    "docker-compose exec mids ab -n 10 -H \"Host: user2.att.com\" http://localhost:5000/buy_a_sword\n",
    "docker-compose exec mids ab -n 10 -H \"Host: user2.att.com\" http://localhost:5000/join_guild\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create a symbolic link to the w205 directory to allow us to run this notebook\n",
    "```\n",
    "docker-compose exec spark bash\n",
    "ln -s /w205 w205\n",
    "exit\n",
    "```\n",
    "\n",
    "We can then create a notebook instance with the following\n",
    "```\n",
    "docker-compose exec spark env PYSPARK_DRIVER_PYTHON=jupyter PYSPARK_DRIVER_PYTHON_OPTS='notebook --no-browser --port 8888 --ip 0.0.0.0 --allow-root' pyspark\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pyspark Code In Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first need to import a couple of python packages to run our code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import udf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create a user defined function \"is_purchase\" which returns True if the event type is \"purchase_sword\" and False if not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@udf('boolean')\n",
    "def is_purchase(event_as_json):\n",
    "    event = json.loads(event_as_json)\n",
    "    if event['event_type'] == 'purchase_sword':\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then read in the raw events from our Kafka topic events (This code will read all of the events in the topic)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_events = spark \\\n",
    "        .read \\\n",
    "        .format(\"kafka\") \\\n",
    "        .option(\"kafka.bootstrap.servers\", \"kafka:29092\") \\\n",
    "        .option(\"subscribe\", \"events\") \\\n",
    "        .option(\"startingOffsets\", \"earliest\") \\\n",
    "        .option(\"endingOffsets\", \"latest\") \\\n",
    "        .load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can filter our the events that were purchase events by using our previously defined function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "purchase_events = raw_events \\\n",
    "        .select(raw_events.value.cast('string').alias('raw'),\n",
    "                raw_events.timestamp.cast('string')) \\\n",
    "        .filter(is_purchase('raw'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can then convert these purchase events into a readable dataframe, with the schema and the output shown below (This is only with the static tests, though it would work with the later infinite apache bench test command as well)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "extracted_purchase_events = purchase_events \\\n",
    "        .rdd \\\n",
    "        .map(lambda r: Row(timestamp=r.timestamp, **json.loads(r.raw))) \\\n",
    "        .toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Accept: string (nullable = true)\n",
      " |-- Host: string (nullable = true)\n",
      " |-- User-Agent: string (nullable = true)\n",
      " |-- event_type: string (nullable = true)\n",
      " |-- sword_type: string (nullable = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "extracted_purchase_events.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------------+---------------+--------------+----------+--------------------+\n",
      "|Accept|             Host|     User-Agent|    event_type|sword_type|           timestamp|\n",
      "+------+-----------------+---------------+--------------+----------+--------------------+\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword|  falchion|2020-12-04 23:44:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword|  falchion|2020-12-04 23:44:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword|  falchion|2020-12-04 23:44:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword|  falchion|2020-12-04 23:44:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword|  falchion|2020-12-04 23:44:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword|  falchion|2020-12-04 23:44:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword|  falchion|2020-12-04 23:44:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword|  falchion|2020-12-04 23:44:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword|  falchion|2020-12-04 23:44:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword|  falchion|2020-12-04 23:44:...|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|purchase_sword|  falchion|2020-12-05 00:06:...|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|purchase_sword|  falchion|2020-12-05 00:06:...|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|purchase_sword|  falchion|2020-12-05 00:06:...|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|purchase_sword|  falchion|2020-12-05 00:06:...|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|purchase_sword|  falchion|2020-12-05 00:06:...|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|purchase_sword|  falchion|2020-12-05 00:06:...|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|purchase_sword|  falchion|2020-12-05 00:06:...|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|purchase_sword|  falchion|2020-12-05 00:06:...|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|purchase_sword|  falchion|2020-12-05 00:06:...|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|purchase_sword|  falchion|2020-12-05 00:06:...|\n",
      "+------+-----------------+---------------+--------------+----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "extracted_purchase_events.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a table for our purchase events, we can then write this to HDFS as parquet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "extracted_purchase_events \\\n",
    "        .write \\\n",
    "        .mode('overwrite') \\\n",
    "        .parquet('/tmp/purchases')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also reproduce this pipeline for the other events by modifying the User Defined Function from earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------------+---------------+----------+----------+--------------------+\n",
      "|Accept|             Host|     User-Agent|event_type|guild_name|           timestamp|\n",
      "+------+-----------------+---------------+----------+----------+--------------------+\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|join_guild|      mage|2020-12-04 23:45:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|join_guild|      mage|2020-12-04 23:45:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|join_guild|      mage|2020-12-04 23:45:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|join_guild|      mage|2020-12-04 23:45:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|join_guild|      mage|2020-12-04 23:45:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|join_guild|      mage|2020-12-04 23:45:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|join_guild|      mage|2020-12-04 23:45:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|join_guild|      mage|2020-12-04 23:45:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|join_guild|      mage|2020-12-04 23:45:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|join_guild|      mage|2020-12-04 23:45:...|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|join_guild|      mage|2020-12-05 00:06:...|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|join_guild|      mage|2020-12-05 00:06:...|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|join_guild|      mage|2020-12-05 00:06:...|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|join_guild|      mage|2020-12-05 00:06:...|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|join_guild|      mage|2020-12-05 00:06:...|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|join_guild|      mage|2020-12-05 00:06:...|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|join_guild|      mage|2020-12-05 00:06:...|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|join_guild|      mage|2020-12-05 00:06:...|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|join_guild|      mage|2020-12-05 00:06:...|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|join_guild|      mage|2020-12-05 00:06:...|\n",
      "+------+-----------------+---------------+----------+----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@udf('boolean')\n",
    "def is_guild(event_as_json):\n",
    "    event = json.loads(event_as_json)\n",
    "    if event['event_type'] == 'join_guild':\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "guild_events = raw_events \\\n",
    "        .select(raw_events.value.cast('string').alias('raw'),\n",
    "                raw_events.timestamp.cast('string')) \\\n",
    "        .filter(is_guild('raw'))\n",
    "        \n",
    "extracted_guild_events = guild_events \\\n",
    "        .rdd \\\n",
    "        .map(lambda r: Row(timestamp=r.timestamp, **json.loads(r.raw))) \\\n",
    "        .toDF()\n",
    "        \n",
    "extracted_guild_events.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "extracted_guild_events \\\n",
    "        .write \\\n",
    "        .mode('overwrite') \\\n",
    "        .parquet('/tmp/guild')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then verify that these wrote to HDFS properly with the following commands\n",
    "```\n",
    "docker-compose exec cloudera hadoop fs -ls /tmp/\n",
    "docker-compose exec cloudera hadoop fs -ls /tmp/purchases\n",
    "docker-compose exec cloudera hadoop fs -ls /tmp/guild\n",
    "```\n",
    "\n",
    "Now that we have stored our tables in HDFS, we can read them back in as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "purchases = spark.read.parquet('/tmp/purchases')\n",
    "guilds = spark.read.parquet('/tmp/guild')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------------+---------------+--------------+----------+--------------------+\n",
      "|Accept|             Host|     User-Agent|    event_type|sword_type|           timestamp|\n",
      "+------+-----------------+---------------+--------------+----------+--------------------+\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword|  falchion|2020-12-04 23:44:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword|  falchion|2020-12-04 23:44:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword|  falchion|2020-12-04 23:44:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword|  falchion|2020-12-04 23:44:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword|  falchion|2020-12-04 23:44:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword|  falchion|2020-12-04 23:44:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword|  falchion|2020-12-04 23:44:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword|  falchion|2020-12-04 23:44:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword|  falchion|2020-12-04 23:44:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword|  falchion|2020-12-04 23:44:...|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|purchase_sword|  falchion|2020-12-05 00:06:...|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|purchase_sword|  falchion|2020-12-05 00:06:...|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|purchase_sword|  falchion|2020-12-05 00:06:...|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|purchase_sword|  falchion|2020-12-05 00:06:...|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|purchase_sword|  falchion|2020-12-05 00:06:...|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|purchase_sword|  falchion|2020-12-05 00:06:...|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|purchase_sword|  falchion|2020-12-05 00:06:...|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|purchase_sword|  falchion|2020-12-05 00:06:...|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|purchase_sword|  falchion|2020-12-05 00:06:...|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|purchase_sword|  falchion|2020-12-05 00:06:...|\n",
      "+------+-----------------+---------------+--------------+----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "purchases.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------------+---------------+----------+----------+--------------------+\n",
      "|Accept|             Host|     User-Agent|event_type|guild_name|           timestamp|\n",
      "+------+-----------------+---------------+----------+----------+--------------------+\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|join_guild|      mage|2020-12-04 23:45:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|join_guild|      mage|2020-12-04 23:45:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|join_guild|      mage|2020-12-04 23:45:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|join_guild|      mage|2020-12-04 23:45:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|join_guild|      mage|2020-12-04 23:45:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|join_guild|      mage|2020-12-04 23:45:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|join_guild|      mage|2020-12-04 23:45:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|join_guild|      mage|2020-12-04 23:45:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|join_guild|      mage|2020-12-04 23:45:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|join_guild|      mage|2020-12-04 23:45:...|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|join_guild|      mage|2020-12-05 00:06:...|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|join_guild|      mage|2020-12-05 00:06:...|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|join_guild|      mage|2020-12-05 00:06:...|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|join_guild|      mage|2020-12-05 00:06:...|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|join_guild|      mage|2020-12-05 00:06:...|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|join_guild|      mage|2020-12-05 00:06:...|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|join_guild|      mage|2020-12-05 00:06:...|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|join_guild|      mage|2020-12-05 00:06:...|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|join_guild|      mage|2020-12-05 00:06:...|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|join_guild|      mage|2020-12-05 00:06:...|\n",
      "+------+-----------------+---------------+----------+----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "guilds.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now register these as tables in SQL, which will allow us to query from them with spark sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "purchases.registerTempTable('purchases')\n",
    "guilds.registerTempTable('guilds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------------+---------------+--------------+----------+--------------------+\n",
      "|Accept|             Host|     User-Agent|    event_type|sword_type|           timestamp|\n",
      "+------+-----------------+---------------+--------------+----------+--------------------+\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword|  falchion|2020-12-04 23:44:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword|  falchion|2020-12-04 23:44:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword|  falchion|2020-12-04 23:44:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword|  falchion|2020-12-04 23:44:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword|  falchion|2020-12-04 23:44:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword|  falchion|2020-12-04 23:44:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword|  falchion|2020-12-04 23:44:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword|  falchion|2020-12-04 23:44:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword|  falchion|2020-12-04 23:44:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword|  falchion|2020-12-04 23:44:...|\n",
      "+------+-----------------+---------------+--------------+----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "purchases_query = spark.sql(\"select * from purchases where Host = 'user1.comcast.com'\")\n",
    "purchases_query.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------------+---------------+----------+----------+--------------------+\n",
      "|Accept|             Host|     User-Agent|event_type|guild_name|           timestamp|\n",
      "+------+-----------------+---------------+----------+----------+--------------------+\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|join_guild|      mage|2020-12-04 23:45:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|join_guild|      mage|2020-12-04 23:45:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|join_guild|      mage|2020-12-04 23:45:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|join_guild|      mage|2020-12-04 23:45:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|join_guild|      mage|2020-12-04 23:45:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|join_guild|      mage|2020-12-04 23:45:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|join_guild|      mage|2020-12-04 23:45:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|join_guild|      mage|2020-12-04 23:45:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|join_guild|      mage|2020-12-04 23:45:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|join_guild|      mage|2020-12-04 23:45:...|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|join_guild|      mage|2020-12-05 00:06:...|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|join_guild|      mage|2020-12-05 00:06:...|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|join_guild|      mage|2020-12-05 00:06:...|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|join_guild|      mage|2020-12-05 00:06:...|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|join_guild|      mage|2020-12-05 00:06:...|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|join_guild|      mage|2020-12-05 00:06:...|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|join_guild|      mage|2020-12-05 00:06:...|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|join_guild|      mage|2020-12-05 00:06:...|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|join_guild|      mage|2020-12-05 00:06:...|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|join_guild|      mage|2020-12-05 00:06:...|\n",
      "+------+-----------------+---------------+----------+----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "guilds_query = spark.sql(\"select * from guilds where guild_name = 'mage'\")\n",
    "guilds_query.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then convert these SQL tables into Pandas Dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accept</th>\n",
       "      <th>Host</th>\n",
       "      <th>User-Agent</th>\n",
       "      <th>event_type</th>\n",
       "      <th>sword_type</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>*/*</td>\n",
       "      <td>user1.comcast.com</td>\n",
       "      <td>ApacheBench/2.3</td>\n",
       "      <td>purchase_sword</td>\n",
       "      <td>falchion</td>\n",
       "      <td>2020-12-04 23:44:58.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Accept               Host       User-Agent      event_type sword_type  \\\n",
       "count      10                 10               10              10         10   \n",
       "unique      1                  1                1               1          1   \n",
       "top       */*  user1.comcast.com  ApacheBench/2.3  purchase_sword   falchion   \n",
       "freq       10                 10               10              10         10   \n",
       "\n",
       "                     timestamp  \n",
       "count                       10  \n",
       "unique                      10  \n",
       "top     2020-12-04 23:44:58.04  \n",
       "freq                         1  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = purchases_query.toPandas()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accept</th>\n",
       "      <th>Host</th>\n",
       "      <th>User-Agent</th>\n",
       "      <th>event_type</th>\n",
       "      <th>guild_name</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>*/*</td>\n",
       "      <td>user1.comcast.com</td>\n",
       "      <td>ApacheBench/2.3</td>\n",
       "      <td>join_guild</td>\n",
       "      <td>mage</td>\n",
       "      <td>2020-12-05 00:06:50.383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Accept               Host       User-Agent  event_type guild_name  \\\n",
       "count      20                 20               20          20         20   \n",
       "unique      1                  2                1           1          1   \n",
       "top       */*  user1.comcast.com  ApacheBench/2.3  join_guild       mage   \n",
       "freq       20                 10               20          20         20   \n",
       "\n",
       "                      timestamp  \n",
       "count                        20  \n",
       "unique                       20  \n",
       "top     2020-12-05 00:06:50.383  \n",
       "freq                          1  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat = guilds_query.toPandas()\n",
    "dat.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Analytics\n",
    "\n",
    "Now that we have SQL tables of subsets of our events, we can run queries and perform simple analytics. We will answer the following questions with queries.\n",
    "\n",
    "- What is the most popular Guild?\n",
    "- How many join guilds events do we see?\n",
    "- How many swords did user 1 purchase?\n",
    "\n",
    "To find the most popular guild, we can run the following query against the guilds table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+\n",
      "|count(1)|guild_name|\n",
      "+--------+----------+\n",
      "|      20|      mage|\n",
      "+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "guilds_query = spark.sql(\"select count(*), guild_name from guilds group by guild_name\")\n",
    "guilds_query.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find that the Mage guild is the most popular (and only) guild in our events with 20 join_guild occurences. We can then query the guilds table again to determine how many guild events we have total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|      20|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "guilds_query = spark.sql(\"select count(*) from guilds\")\n",
    "guilds_query.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, we find that there are 20 join_guild events overall. Next, we can query the purchases table to see how many swords user 1 purchased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|      10|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "purchases_query = spark.sql(\"select count(*) from purchases where Host = 'user1.comcast.com'\")\n",
    "purchases_query.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find that User 1 has purchased 10 swords. Next, we want to modify our pipeline to allow for stream processing. First, we will need to import some new packages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stream Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, from_json\n",
    "from pyspark.sql.types import StructType, StructField, StringType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now define a schema for our purchase sword events and create a new User Defined Function that also filters out purchase sword events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def purchase_sword_event_schema():\n",
    "    \"\"\"\n",
    "    root\n",
    "    |-- Accept: string (nullable = true)\n",
    "    |-- Host: string (nullable = true)\n",
    "    |-- User-Agent: string (nullable = true)\n",
    "    |-- event_type: string (nullable = true)\n",
    "    |-- timestamp: string (nullable = true)\n",
    "    \"\"\"\n",
    "    return StructType([\n",
    "        StructField(\"Accept\", StringType(), True),\n",
    "        StructField(\"Host\", StringType(), True),\n",
    "        StructField(\"User-Agent\", StringType(), True),\n",
    "        StructField(\"event_type\", StringType(), True),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@udf('boolean')\n",
    "def is_sword_purchase(event_as_json):\n",
    "    \"\"\"udf for filtering events\n",
    "    \"\"\"\n",
    "    event = json.loads(event_as_json)\n",
    "    if event['event_type'] == 'purchase_sword':\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start the stream processing pipeline, we will want to create infinite tests. This can be done with the following apache bench command (Will generate 10 purchase sword events every 5 seconds until manually stopped)\n",
    "```\n",
    "while true; do docker-compose exec mids ab -n 10 -H \"Host: user1.comcast.com\" http://localhost:5000/purchase_a_sword; sleep 5; done\n",
    "```\n",
    "\n",
    "We can now create our stream processing pipeline using the following (Will write a new parquet file to the sword_purchases directory every 10 seconds)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_events = spark \\\n",
    "        .readStream \\\n",
    "        .format(\"kafka\") \\\n",
    "        .option(\"kafka.bootstrap.servers\", \"kafka:29092\") \\\n",
    "        .option(\"subscribe\", \"events\") \\\n",
    "        .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sword_purchases = raw_events \\\n",
    "        .filter(is_sword_purchase(raw_events.value.cast('string'))) \\\n",
    "        .select(raw_events.value.cast('string').alias('raw_event'),\n",
    "                raw_events.timestamp.cast('string'),\n",
    "                from_json(raw_events.value.cast('string'),\n",
    "                          purchase_sword_event_schema()).alias('json')) \\\n",
    "        .select('raw_event', 'timestamp', 'json.*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sink = sword_purchases \\\n",
    "        .writeStream \\\n",
    "        .format(\"parquet\") \\\n",
    "        .option(\"checkpointLocation\", \"/tmp/checkpoints_for_sword_purchases\") \\\n",
    "        .option(\"path\", \"/tmp/sword_purchases\") \\\n",
    "        .trigger(processingTime=\"10 seconds\") \\\n",
    "        .start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to check the functionality of our pipeline, we can continue to run the following command and see how our number of files increases\n",
    "```\n",
    "docker-compose exec cloudera hadoop fs -ls /tmp/sword_purchases\n",
    "```\n",
    "\n",
    "When we want to stop writing files to HDFS, we can simply run the following line of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sink.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now, if we want to want to look at our tables, we can use Hive and Presto. First we can create and external table for schema on read in Hive\n",
    "```\n",
    "docker-compose exec cloudera hive\n",
    "```\n",
    "\n",
    "Once we are in Hive, we can run the following command to create the external table in the sword_purchases directory of HDFS\n",
    "```\n",
    "create external table if not exists default.sword_purchases (Accept string, Host string, User_Agent string, event_type string, timestamp string) stored as parquet location '/tmp/sword_purchases'  tblproperties (\"parquet.compress\"=\"SNAPPY\");\n",
    "```\n",
    "\n",
    "We can then run the following code to check if it created our table and to look at the table it created\n",
    "\n",
    "```\n",
    "hive> show tables;\n",
    "OK\n",
    "sword_purchases\n",
    "```\n",
    "This is the result we should see if our table was properly created. We can then look at the output we should have from describing the table\n",
    "\n",
    "```\n",
    "hive> desc sword_purchases;\n",
    "OK\n",
    "accept                  string                                      \n",
    "host                    string                                      \n",
    "user_agent              string                                      \n",
    "event_type              string                                      \n",
    "timestamp               string\n",
    "```\n",
    "\n",
    "We can then use the following to exit Hive\n",
    "```\n",
    "exit;\n",
    "```\n",
    "\n",
    "Now, we can see if our data in the HDFS is queryable through Presto. We can first start Presto\n",
    "```\n",
    "docker-compose exec presto presto --server presto:8080 --catalog hive --schema default\n",
    "```\n",
    "\n",
    "We can then run the following to see the tables we have (and we find that we have the sword_purchases table)\n",
    "```\n",
    "show tables;\n",
    "```\n",
    "\n",
    "We can now query the sword_purchases table to make sure we can do analysis in Presto\n",
    "```\n",
    "select count(*) from sword_purchases;\n",
    "```\n",
    "The result of the query is below. We can see that when we ran this query, there were 200 sword purchases.\n",
    "```\n",
    "presto:default> select count(*) from sword_purchases;\n",
    " _col0 \n",
    "-------\n",
    "   200 \n",
    "(1 row)\n",
    "```\n",
    "\n",
    "We can also run one more query to be sure\n",
    "```\n",
    "select * from sword_purchases limit 5;\n",
    "```\n",
    "\n",
    "And below is the output\n",
    "```\n",
    "-------------------------------------------------------------------------------------------------------------------------------------------+------------------------\n",
    " {\"Host\": \"user1.comcast.com\", \"sword_type\": \"falchion\", \"event_type\": \"purchase_sword\", \"Accept\": \"*/*\", \"User-Agent\": \"ApacheBench/2.3\"} | 2020-12-05 00:32:35.069\n",
    " {\"Host\": \"user1.comcast.com\", \"sword_type\": \"falchion\", \"event_type\": \"purchase_sword\", \"Accept\": \"*/*\", \"User-Agent\": \"ApacheBench/2.3\"} | 2020-12-05 00:32:35.073\n",
    " {\"Host\": \"user1.comcast.com\", \"sword_type\": \"falchion\", \"event_type\": \"purchase_sword\", \"Accept\": \"*/*\", \"User-Agent\": \"ApacheBench/2.3\"} | 2020-12-05 00:32:35.075\n",
    " {\"Host\": \"user1.comcast.com\", \"sword_type\": \"falchion\", \"event_type\": \"purchase_sword\", \"Accept\": \"*/*\", \"User-Agent\": \"ApacheBench/2.3\"} | 2020-12-05 00:32:35.079\n",
    " {\"Host\": \"user1.comcast.com\", \"sword_type\": \"falchion\", \"event_type\": \"purchase_sword\", \"Accept\": \"*/*\", \"User-Agent\": \"ApacheBench/2.3\"} | 2020-12-05 00:32:35.083\n",
    "(5 rows)\n",
    "```\n",
    "\n",
    "We can then stop presto by using the exit command\n",
    "```\n",
    "exit;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have finished all parts of the project, we can go ahead and stop our Flask Server (And our notebook server) with CTRL C. We can then bring down our cluster and check to ensure that it went down properly with \n",
    "```\n",
    "docker-compose down\n",
    "docker-compose ps\n",
    "docker ps -a\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
